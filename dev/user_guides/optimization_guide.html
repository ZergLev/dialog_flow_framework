<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Optimization Guide &#8212; Python  documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=4f649999" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css?v=039e1c02" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js?v=b3ba4146"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=4825356b"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Tutorials" href="../tutorials.html" />
    <link rel="prev" title="Superset guide" href="superset_guide.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="optimization-guide">
<h1>Optimization Guide<a class="headerlink" href="#optimization-guide" title="Permalink to this heading">¶</a></h1>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this heading">¶</a></h2>
<p>When optimizing a dialog service to provide the best possible user experience,
it’s essential to identify and address performance issues.
Similar to any complex system, a dialog service can have performance bottlenecks at various levels.
These bottlenecks can occur during I/O operations like receiving and sending messages,
as well as when synchronizing service states with a database.
As the number of callbacks in the script and pipeline increases,
the performance of DFF classes can degrade leading to longer response time.</p>
<p>As a result, it becomes necessary to locate the part of the pipeline that is causing issues, so that
further optimization steps can be taken. DFF provides several tools that address the need for
profiling individual system components. This guide will walk you through the process
of using these tools in practice and optimizing the profiled application.</p>
</section>
<section id="profiling-with-locust-testing">
<h2>Profiling with Locust testing<a class="headerlink" href="#profiling-with-locust-testing" title="Permalink to this heading">¶</a></h2>
<p><a class="reference external" href="https://locust.io/">Locust</a> is a tool for load testing web applications that
simultaneously spawns several user agents that execute a pre-determined behavior
against the target application. Assuming that your pipeline is integrated into a web
server application, like Flask or FastAPI, that is not strongly impacted by the load,
the load testing reveals how well your pipeline would scale to a highly loaded environment.
Using this approach, you can also measure the scalability of each component in your pipeline,
if you take advantage of the Opentelemetry package bundled with the library (<cite>stats</cite> extra required)
as described below.</p>
<p>Since Locust testing can only target web apps,
this approach only applies if you integrate your dialog pipeline into a web application.
The <a class="reference external" href="../tutorials/tutorials.messengers.web_api_interface.1_fastapi.py">FastAPI integration tutorial</a>
shows the most straightforward way to do this.
At this stage, you will also need to instrument the pipeline components that you want to additionally profile
using <cite>extractor functions</cite>. Put simply, you are decorating the components of the pipeline
with functions that can report their performance, e.g. their execution time or the CPU load.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You can get more info on how instrumentation is done and statistics are collected
in the <a class="reference external" href="../tutorials/tutorials.stats.1_extractor_functions.py">stats tutorial</a>.</p>
</div>
<p>When you are done setting up the instrumentation, you can launch the web server to accept connections from locust.</p>
<p>The final step is to run a Locust file which will result in artificial load traffic being generated and sent to your server.
A Locust file is a script that implements the behavior of artificial users,
i.e. the requests to the server that will be made during testing.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>An example Locust script along with instructions on how to run it can be found in the
<a class="reference external" href="../tutorials/tutorials.messengers.web_api_interface.3_load_testing_with_locust.py">load testing tutorial</a>.
The simplest way, however, is to pass a locust file to the Python interpreter.</p>
</div>
<p>Once Locust is running, you can access its GUI, where you can set the number of users to emulate.
After configuring this parameter, the active phase of testing will begin,
and the results will become accessible on an interactive dashboard.
These reported values include timing data, such as the average response time of your service,
allowing you to assess the performance’s reasonableness and impact on user experience.</p>
<p>The data provided by extractor functions will be available in the Clickhouse database;
you can view it using the Superset dashboard (see <a class="reference external" href="./superset_guide.html">instructions</a>)
or analyze it with your own queries using the Clickhouse client.</p>
</section>
<section id="profiling-context-storages">
<h2>Profiling context storages<a class="headerlink" href="#profiling-context-storages" title="Permalink to this heading">¶</a></h2>
<p>Benchmarking the performance of context storage is crucial to understanding
how different storage methods impact your dialog service’s efficiency.
This process involves running tests to measure the speed and reliability of various context storage solutions.
Given the exact configuration of your system, one or the other database type may be performing more efficiently,
so you may prefer to change your database depending on the testing results.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The exact instructions of how the testing can be carried out are available in the
<a class="reference external" href="../tutorials/tutorials.context_storages.8_db_benchmarking.py">DB benchmarking tutorial</a>.</p>
</div>
</section>
<section id="optimization-techniques">
<h2>Optimization techniques<a class="headerlink" href="#optimization-techniques" title="Permalink to this heading">¶</a></h2>
<p>Aside from choosing an appropriate database type, there exists a number of other recommendations
that may help you improve the efficiency of your service.</p>
<ul class="simple">
<li><p>Firstly, follow the DRY principle not only with regard to your code, but also with regard to
computational operations. In other words, you have to make sure that your callback functions work only once
during a dialog turn and only when needed. E.g. you can take note of the <cite>conditions</cite> api available as a part
of the <cite>Pipeline</cite> module: while normally a pipeline service runs every turn, you can restrict it
to only run on turns when a particular condition is satisfied, greatly reducing
the number of performed actions (see the
<a class="reference external" href="../tutorials/tutorials.pipeline.4_groups_and_conditions_full.py">Groups and Conditions tutorial</a>).</p></li>
<li><p>Using caching for resource-consuming callbacks and actions may also prove to be a helpful strategy.
In this manner, you can improve the computational efficiency of your pipeline,
while making very few changes to the code itself. DFF includes a caching mechanism
for response functions. However, the simplicity
of the DFF API makes it easy to integrate any custom caching solutions that you may come up with.
See the <a class="reference external" href="../tutorials/tutorials.utils.1_cache.py">Cache tutorial</a>.</p></li>
<li><p>Finally, be mindful about the use of computationally expensive algorithms, like NLU classifiers
or LLM-based generative networks, since those require a great deal of time and resources
to produce an answer. In case you need to use one, take full advantage of caching along with
other means to relieve the computational load imposed by neural networks such as message queueing.</p></li>
</ul>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">Python</a></h1>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../get_started.html">Getting started</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../user_guides.html">User guides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference.html">API reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../development.html">Development</a></li>
<li class="toctree-l1"><a class="reference internal" href="../community.html">Community</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about_us.html">About us</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="../user_guides.html">User guides</a><ul>
      <li>Previous: <a href="superset_guide.html" title="previous chapter">Superset guide</a></li>
      <li>Next: <a href="../tutorials.html" title="next chapter">Tutorials</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="../_sources/user_guides/optimization_guide.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>